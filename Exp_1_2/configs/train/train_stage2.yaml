model:
  cldm:
    target: diffbir.model.cldm.ControlLDM
    params:
      latent_scale_factor: 0.18215
      unet_cfg:
        use_checkpoint: True
        image_size: 32 # unused
        in_channels: 4
        out_channels: 4
        model_channels: 320
        attention_resolutions: [ 4, 2, 1 ]
        num_res_blocks: 2
        channel_mult: [ 1, 2, 4, 4 ]
        num_head_channels: 64 # need to fix for flash-attn
        use_spatial_transformer: True
        use_linear_in_transformer: True
        transformer_depth: 1
        context_dim: 1024  # 特征放进context中 原来是1024
        rgb_dim: 768    # 【融合RGB图像方法二】
        legacy: False
      vae_cfg:
        embed_dim: 4
        ddconfig:
          double_z: true
          z_channels: 4
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult:
          - 1
          - 2
          - 4
          - 4
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
      clip_cfg:
        embed_dim: 1024
        vision_cfg:
          image_size: 224
          layers: 32
          width: 1280
          head_width: 80
          patch_size: 14
        text_cfg:
          context_length: 77
          vocab_size: 49408
          width: 1024
          heads: 16
          layers: 24
        layer: "penultimate"
      controlnet_cfg:
        use_checkpoint: True
        image_size: 32 # unused
        in_channels: 4
        hint_channels: 4  # 【融合RGB图像方法一】原来是4，这里实验融合RGB图像更改为8
        model_channels: 320
        attention_resolutions: [ 4, 2, 1 ]
        num_res_blocks: 2
        channel_mult: [ 1, 2, 4, 4 ]
        num_head_channels: 64 # need to fix for flash-attn
        use_spatial_transformer: True
        use_linear_in_transformer: True
        transformer_depth: 1
        context_dim: 1024  # 特征放进context中 原来是1024
        rgb_dim: 768      # 【融合RGB图像方法二】
        legacy: False

  swinir:
    target: diffbir.model.swinir.SwinIR
    params:
      img_size: 64
      patch_size: 1
      in_chans: 3
      embed_dim: 180
      depths: [6, 6, 6, 6, 6, 6, 6, 6]
      num_heads: [6, 6, 6, 6, 6, 6, 6, 6]
      window_size: 8
      mlp_ratio: 2
      sf: 8
      img_range: 1.0
      upsampler: "nearest+conv"
      resi_connection: "1conv"
      unshuffle: True
      unshuffle_scale: 8

  hi_diff:
    # general settings
    name:  test_HI_Diff_GoPro
    model_type: HI_Diff_S2
    scale: 1
    num_gpu: 1  # set num_gpu: 0 for cpu mode
    manual_seed: 100

    is_train: False
    dist: False

    # network structures
    network_g:
      type: Transformer
      inp_channels: 3
      out_channels: 3
      dim: 48
      num_blocks: [3,5,6,6]
      num_refinement_blocks: 4
      heads: [1,2,4,8]
      ffn_expansion_factor: 2.66
      bias: False
      LayerNorm_type: WithBias
      dual_pixel_task: False
      embed_dim: 64
      group: 4 # N=4*4

    network_le:
      type: latent_encoder_gelu
      in_chans: 6
      embed_dim: 64 # same as above
      block_num: 6
      group: 4 # same as above
      stage: 1
      patch_expansion: 0.5
      channel_expansion: 4

    network_le_dm:
      type: latent_encoder_gelu
      in_chans: 3
      embed_dim: 64 # same as above
      block_num: 6
      group: 4 # same as above
      stage: 2
      patch_expansion: 0.5
      channel_expansion: 4

    network_d:
      type: denoising
      in_channel: 256 # (embed_dim*4)
      out_channel: 256 # (embed_dim*4)
      inner_channel: 512
      block_num: 4
      group: 4 # same as above
      patch_expansion: 0.5
      channel_expansion: 2

    diffusion_schedule:
      apply_ldm: False
      schedule: linear
      timesteps: 8
      linear_start: 0.1 # 1e-6
      linear_end: 0.99 # 1e-2

    # path
    path:
      pretrain_network_g: weights/experiment_1/net_g_latest.pth
      # param_key_g: params
      strict_load_g: true

      pretrain_network_le_dm: weights/experiment_1/net_le_dm_latest.pth
      # param_key_g: params
      strict_load_le_dm: true

      pretrain_network_d: weights/experiment_1/net_d_latest.pth
      # param_key_g: params
      strict_load_d: true

      resume_state: ~
        
    # validation settings
    val:
      save_img: True
      suffix: ''
      selfensemble_testing: False

      metrics:
        psnr: # metric name, can be arbitrary
          type: calculate_psnr
          crop_border: 0
          test_y_channel: false
        ssim:
          type: calculate_ssim
          crop_border: 0
          test_y_channel: false

  diffusion:
    target: diffbir.model.gaussian_diffusion.Diffusion
    params:
      linear_start: 0.00085
      linear_end: 0.0120
      timesteps: 1000
      zero_snr: False
      parameterization: eps

dataset:
  train:
    target: diffbir.dataset.codeformer.CodeformerDataset
    params:
      # training file list path
      # file_list: 
      file_list_HQ: datasets/ZZCX_2_1/train/HQ.list
      file_list_LQ: datasets/ZZCX_2_1/train/LQ.list
      # file_list_condition: datasets/ZZCX_01_20/train/condition_edge.list
      # file_list_condition: datasets/ZZCX_01_20/train/condition_RGB.list
      file_list_edge: datasets/ZZCX_2_1/train_edge/condition_edge.list
      file_list_RGB: datasets/ZZCX_2_1/train_RGB/condition_RGB.list
      file_backend_cfg:
        target: diffbir.dataset.file_backend.HardDiskBackend
      out_size: 512
      crop_type: center
      blur_kernel_size: 41
      kernel_list: ['iso', 'aniso']
      kernel_prob: [0.5, 0.5]
      blur_sigma: [0.1, 12]
      downsample_range: [1, 12]
      noise_range: [0, 15]
      jpeg_range: [30, 100]

batch_transform:
  target: diffbir.dataset.batch_transform.IdentityBatchTransform

train:
  # pretrained sd v2.1 path
  sd_path: weights/v2-1_512-ema-pruned.ckpt
  # experiment directory path
  exp_dir: myexperiments/experiment6/stage2_1
  # stage 1 swinir path.
  # In our paper, we use SwinIR trained on ImageNet-1k with codeformer degradation.
  # swinir_path: experiment4/stage1/checkpoints/0150000.pt  
  hi_diff_path:
  # swinir_path: weights/general_swinir_v1.ckpt
  learning_rate: 1e-4
  # ImageNet 1k (1.3M images)
  # batch size = 192, lr = 1e-4, total training steps = 25k
  # Our filtered laion2b-en (15M images)
  # batch size = 256, lr = 1e-4 (first 30k), 1e-5 (next 50k), total training steps = 80k
  batch_size: 16         # 256
  num_workers: 4
  train_steps: 30000     # 30000
  log_every: 50
  ckpt_every: 10000
  image_every: 1000
  resume: 
  noise_aug_timestep: 0
