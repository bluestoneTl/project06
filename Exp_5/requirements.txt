# --extra-index-url https://download.pytorch.org/whl/cu118
# torch==2.2.2+cu118
# torchvision==0.17.2+cu118
# torchaudio==2.2.2+cu118
# xformers==0.0.25.post1+cu118
# pip install torch==1.12.0+cu113 torchvision==0.13.0+cu113 torchaudio==0.12.0 --extra-index-url https://download.pytorch.org/whl/cu113
# pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113
# xformers==0.0.16    # https://blog.csdn.net/wangning6252820/article/details/134056100
# wget https://anaconda.org/xformers/xformers/0.0.16/download/linux-64/xformers-0.0.16-py310_cu11.3_pyt1.12.1.tar.bz2
# conda install xformers-0.0.16-py310_cu11.3_pyt1.12.1.tar.bz2
# python -m xformers.info
omegaconf==2.3.0
accelerate==0.28.0 
einops==0.7.0
opencv_python==4.9.0.80
scipy==1.12.0
ftfy==6.2.0
regex==2023.12.25
python-dateutil==2.9.0.post0
timm==0.9.16
pytorch-lightning==1.9.5 # only for loading pretrained sd weight   # pip install pytorch-lightning==2.2.1 torch限制，原来是
tensorboard==2.16.2 # for tensorboard event visualization
protobuf==4.25.3 # for tensorboard
lpips==0.1.4
facexlib==0.3.0
gradio==4.43.0
polars==1.12.0
torchsde==0.2.6
bitsandbytes==0.44.1

# requirements for llava
transformers==4.37.2
tokenizers==0.15.1
sentencepiece==0.1.99

# requirements for ram
fairscale==0.4.4


#  某个推理时候的问题
# cd /root/anaconda3/envs/diffbir/lib/python3.10/site-packages/bitsandbytes/
# cp libbitsandbytes_cuda117.so libbitsandbytes_cpu.so


# Could not find the bitsandbytes CUDA binary at 
# PosixPath('/root/anaconda3/envs/diffbir/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda113.so
Pillow==9.5.0




import torch
from torchvision import transforms
from PIL import Image
from diffbir.model.swinir import SwinIR
import os
# python run_swinir_save_img.py
# 配置模型参数
img_size = 64
patch_size = 1
in_chans = 3
embed_dim = 180
depths = [6, 6, 6, 6, 6, 6, 6, 6]
num_heads = [6, 6, 6, 6, 6, 6, 6, 6]
window_size = 8
mlp_ratio = 2
sf = 8
img_range = 1.0
upsampler = "nearest+conv"
resi_connection = "1conv"
unshuffle = True
unshuffle_scale = 8

swinir = SwinIR(
    img_size=img_size,
    patch_size=patch_size,
    in_chans=in_chans,
    embed_dim=embed_dim,
    depths=depths,
    num_heads=num_heads,
    window_size=window_size,
    mlp_ratio=mlp_ratio,
    sf=sf,
    img_range=img_range,
    upsampler=upsampler,
    resi_connection=resi_connection,
    unshuffle=unshuffle,
    unshuffle_scale=unshuffle_scale
)

swinir_path = "weights/my_swinir.pth" 
sd = torch.load(swinir_path, map_location="cpu")
if "state_dict" in sd:
    sd = sd["state_dict"]
sd = {
    (k[len("module."):] if k.startswith("module.") else k): v
    for k, v in sd.items()
}
swinir.load_state_dict(sd, strict=True)
swinir.eval()

preprocess = transforms.Compose([
    transforms.ToTensor()
])
postprocess = transforms.Compose([
    transforms.ToPILImage()
])

# 定义输入和输出文件夹路径
input_folder = "datasets/ZZCX_2_1/test/LQ_mini"  
output_folder = "datasets/ZZCX_2_1/test/swinir_LQ"  
os.makedirs(output_folder, exist_ok=True)

# 遍历输入文件夹中的所有图片
for filename in os.listdir(input_folder):
    if filename.endswith(('.png', '.jpg', '.jpeg')):
        # 读取图片
        image_path = os.path.join(input_folder, filename)
        image = Image.open(image_path).convert('RGB')

        # 预处理图片
        input_tensor = preprocess(image).unsqueeze(0)  # 添加批次维度

        # 使用 SwinIR 模型处理图片
        with torch.no_grad():
            output_tensor = swinir(input_tensor)

        # 后处理输出结果
        output_image = postprocess(output_tensor.squeeze(0).clamp(0, 1))

        # 保存处理后的图片
        output_path = os.path.join(output_folder, filename)
        output_image.save(output_path)
        print(f"Processed and saved {output_path}")

print("All images have been processed and saved.")